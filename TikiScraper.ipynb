{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web scraping from Tiki.vn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crawl product data on TIKI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get product IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import re    \n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36'}\n",
    "\n",
    "def crawl_product_id_with_html(url):\n",
    "    product_list = []\n",
    "    i = 1\n",
    "    with requests.Session() as s:\n",
    "        while (True):\n",
    "            print(\"Crawl page: \", i)\n",
    "            response = s.get(url.format(i), headers=headers)\n",
    "            soup = bs(response.content)\n",
    "\n",
    "            product_box = soup.find_all('a', class_='product-item')\n",
    "            if (len(product_box) == 0):\n",
    "                break\n",
    "\n",
    "\n",
    "            for product in product_box:\n",
    "                product_link = product['href']\n",
    "                matched = re.search('-p(\\d+).html', product_link)\n",
    "                if matched:\n",
    "                    product_list.append(matched.group(1))\n",
    "                    print(matched.group(1))\n",
    "                else:\n",
    "                    product_list.append(\"N/A\")\n",
    "            i += 1\n",
    "\n",
    "    return product_list\n",
    "\n",
    "def crawl_product_id_with_api(category):\n",
    "    api_url = 'https://tiki.vn/api/v2/products?limit=300&category={}&page={}'.format(category, '{}')\n",
    "    product_list = []\n",
    "    i = 1\n",
    "    while (True):\n",
    "        passed = False\n",
    "        while (passed == False):\n",
    "            try:\n",
    "                response = requests.get(api_url.format(i), headers=headers)\n",
    "                product_dict = json.loads(response.content)\n",
    "                passed = True\n",
    "\n",
    "            except Exception as e:\n",
    "                if isinstance(e, KeyboardInterrupt):\n",
    "                    sys.exit()\n",
    "                print(\"Connection error\")\n",
    "        \n",
    "        if product_dict['data'] == []:\n",
    "            break\n",
    "\n",
    "        for product_data in product_dict['data']:\n",
    "            product_list.append(product_data['id'])\n",
    "        i += 1\n",
    "\n",
    "    return product_list\n",
    "\n",
    "def save_pickle(data, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "    print(\"Save file: \", filename)\n",
    "\n",
    "def load_pickle(product_file):\n",
    "    with open(product_file, \"rb\") as input_file:\n",
    "        data = pickle.load(input_file)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_summary = [\n",
    "    1789, 4221, 1815, 1846, 1801, 1882, 1883, 4384, 2549, 1520, 931, 915, 6000, 8371, 1703, 1686, 27498, \n",
    "    976, 27616, 1975, 8594, 17166, 8322, 11312\n",
    "]\n",
    "\n",
    "product_list_all = []\n",
    "for category in categories_summary:\n",
    "    product_list = crawl_product_id_with_api(category)\n",
    "    if product_list != []:\n",
    "        print(\"No. Product ID: \", len(product_list), 'with category ', category)\n",
    "        product_list_all = product_list_all + product_list\n",
    "\n",
    "print(\"No. Product ID: \", len(product_list_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_list_all = load_pickle('product_id_summary.pkl')\n",
    "product_list_all = set(product_list_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(product_list_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(product_list_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save product id for backup\n",
    "product_list_all = set(product_list_all)\n",
    "save_pickle(product_list_all , 'product_id_summary.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get products info for each ID using Tiki API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_product(product_id):\n",
    "    product_url='https://tiki.vn/api/v2/products/{}'\n",
    "    passed = False\n",
    "    product_info = None\n",
    "    while (passed == False):\n",
    "        try:\n",
    "            response = requests.get(product_url.format(product_id), headers=headers)\n",
    "            if (response.status_code == 200):\n",
    "                passed = True\n",
    "        except Exception as e:\n",
    "            if isinstance(e, KeyboardInterrupt):\n",
    "                sys.exit()\n",
    "            print(\"Connection error\")\n",
    "    product_info = json.loads(response.text)\n",
    "    return product_info\n",
    "\n",
    "products_info = []\n",
    "for index, product_id in enumerate(set(product_list_all)):\n",
    "    product_info = crawl_product(product_id)\n",
    "    products_info.append(product_info)\n",
    "    if index%100 == 0:\n",
    "        print(\"Crawl {} products\".format(index))\n",
    "        save_pickle(products_info, 'products_info_summary_0_{}.pkl'.format(index))\n",
    "    if index%5000 == 0:\n",
    "        save_pickle(products_info, 'products_info_summary_0_{}.pkl'.format(index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert string info from TIKI API to Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_df = pd.DataFrame(products_info)\n",
    "info_df.to_csv('products_info_raw.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crawl TIKI reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_api_url = 'https://tiki.vn/api/v2/reviews?product_id={}&sort=score%7Cdesc,id%7Cdesc,stars%7Call&page={}&limit=1000&include=comments'\n",
    "def crawl_review_from_id(product_id):\n",
    "    i = 1\n",
    "    review_list = []\n",
    "    while True:\n",
    "        passed = False\n",
    "        while (passed == False):\n",
    "            try:\n",
    "                response = requests.get(review_api_url.format(product_id, i), headers=headers)\n",
    "                review_data = json.loads(response.content)['data']\n",
    "                passed = True\n",
    "            except Exception as e:\n",
    "                if isinstance(e, KeyboardInterrupt):\n",
    "                    sys.exit()\n",
    "                print(\"Connection error\")\n",
    "\n",
    "        if review_data == []:\n",
    "            break\n",
    "        review_list = review_list + review_data\n",
    "        i = i + 1\n",
    "    return review_list\n",
    "product_reviews = []\n",
    "for index, product_id in enumerate(set(product_list_all)): \n",
    "    product_review = crawl_review_from_id(product_id)\n",
    "    product_reviews = product_reviews + product_review\n",
    "    if index%100==0:\n",
    "        print('Crawled {} reviews from {} products'.format(len(product_reviews), index))\n",
    "        save_pickle(product_reviews, 'products_review_summary_0_{}.pkl'.format(index))\n",
    "    if index%5000 == 0:\n",
    "        save_pickle(product_reviews, 'products_review_summary_0_{}.pkl'.format(index))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert string info from TIKI API to Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df = pd.DataFrame(product_reviews)\n",
    "review_df.to_csv('products_review_raw.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "ds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
